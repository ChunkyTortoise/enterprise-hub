============================= test session starts ==============================
platform darwin -- Python 3.13.0, pytest-7.4.3, pluggy-1.6.0 -- /Library/Frameworks/Python.framework/Versions/3.13/bin/python3.13
cachedir: .pytest_cache
rootdir: /Users/Cave/Desktop/enterprise-hub/EnterpriseHub
configfile: pyproject.toml
plugins: anyio-4.12.0, cov-4.1.0, mock-3.12.0
collecting ... collected 301 items

tests/unit/test_agent_logic.py::test_render_successful_analysis FAILED   [  0%]
tests/unit/test_agent_logic.py::test_render_no_news_found FAILED         [  0%]
tests/unit/test_agent_logic.py::test_render_no_ticker_entered FAILED     [  0%]
tests/unit/test_agent_logic.py::test_render_handles_exception FAILED     [  1%]
tests/unit/test_agent_logic.py::TestClaudeSentiment::test_get_api_key_toggle_shown PASSED [  1%]
tests/unit/test_agent_logic.py::TestClaudeSentiment::test_no_api_key_caption_shown PASSED [  1%]
tests/unit/test_agent_logic.py::TestClaudeSentiment::test_get_api_key_from_env PASSED [  2%]
tests/unit/test_agent_logic.py::TestSentimentAnalyzerClaude::test_analyze_sentiment_with_claude_success PASSED [  2%]
tests/unit/test_agent_logic.py::TestSentimentAnalyzerClaude::test_analyze_sentiment_with_claude_fallback PASSED [  2%]
tests/unit/test_agent_logic.py::TestSentimentAnalyzerClaude::test_analyze_sentiment_with_claude_no_news PASSED [  3%]
tests/unit/test_agent_logic.py::TestSentimentAnalyzerClaude::test_analyze_sentiment_with_claude_not_available PASSED [  3%]
tests/unit/test_content_engine.py::TestContentEngineTemplates::test_all_templates_exist PASSED [  3%]
tests/unit/test_content_engine.py::TestContentEngineTemplates::test_templates_have_required_fields PASSED [  4%]
tests/unit/test_content_engine.py::TestContentEngineTemplates::test_all_tones_exist PASSED [  4%]
tests/unit/test_content_engine.py::TestContentEngineTemplates::test_tones_have_instructions PASSED [  4%]
tests/unit/test_content_engine.py::TestContentEngineAPIKeyHandling::test_get_api_key_from_env PASSED [  5%]
tests/unit/test_content_engine.py::TestContentEngineAPIKeyHandling::test_get_api_key_from_session_state PASSED [  5%]
tests/unit/test_content_engine.py::TestContentEngineAPIKeyHandling::test_get_api_key_returns_none_when_missing PASSED [  5%]
tests/unit/test_content_engine.py::TestContentEngineGeneration::test_generate_post_success PASSED [  6%]
tests/unit/test_content_engine.py::TestContentEngineGeneration::test_generate_post_api_error PASSED [  6%]
tests/unit/test_content_engine.py::TestContentEngineGeneration::test_generate_post_with_optional_params PASSED [  6%]
tests/unit/test_content_engine.py::TestContentEnginePromptConstruction::test_prompt_includes_template_prefix PASSED [  7%]
tests/unit/test_content_engine.py::TestContentEnginePromptConstruction::test_prompt_includes_tone_instructions PASSED [  7%]
tests/unit/test_content_engine.py::TestContentEngineImportSafety::test_anthropic_available_flag PASSED [  7%]
tests/unit/test_content_engine.py::TestContentEngineEdgeCases::test_generate_post_with_empty_keywords PASSED [  8%]
tests/unit/test_content_engine.py::TestContentEngineEdgeCases::test_generate_post_with_whitespace_only_keywords PASSED [  8%]
tests/unit/test_content_engine.py::TestContentEngineEdgeCases::test_generate_post_with_very_long_topic PASSED [  8%]
tests/unit/test_content_engine.py::TestContentEngineEdgeCases::test_generate_post_with_special_characters PASSED [  9%]
tests/unit/test_content_engine.py::TestContentEngineEdgeCases::test_validate_template_and_tone_invalid_template PASSED [  9%]
tests/unit/test_content_engine.py::TestContentEngineEdgeCases::test_validate_template_and_tone_invalid_tone PASSED [  9%]
tests/unit/test_content_engine.py::TestContentEngineEdgeCases::test_validate_template_and_tone_both_invalid PASSED [ 10%]
tests/unit/test_content_engine.py::TestContentEngineEdgeCases::test_generate_post_with_empty_api_key PASSED [ 10%]
tests/unit/test_content_engine.py::TestContentEngineEdgeCases::test_generate_post_with_whitespace_api_key PASSED [ 10%]
tests/unit/test_content_engine.py::TestContentEngineEdgeCases::test_generate_post_with_empty_topic PASSED [ 11%]
tests/unit/test_content_engine.py::TestContentEngineEdgeCases::test_build_prompt_structure PASSED [ 11%]
tests/unit/test_content_engine.py::TestContentEngineRateLimiting::test_retry_on_rate_limit_success_after_retry PASSED [ 11%]
tests/unit/test_content_engine.py::TestContentEngineRateLimiting::test_retry_exhausted_on_rate_limit PASSED [ 12%]
tests/unit/test_content_engine.py::TestContentEngineRateLimiting::test_exponential_backoff_delays PASSED [ 12%]
tests/unit/test_content_engine.py::TestContentEngineMalformedResponses::test_api_returns_empty_content_list PASSED [ 12%]
tests/unit/test_content_engine.py::TestContentEngineMalformedResponses::test_api_returns_none_content PASSED [ 13%]
tests/unit/test_content_engine.py::TestContentEngineMalformedResponses::test_api_returns_malformed_content_object PASSED [ 13%]
tests/unit/test_content_engine.py::TestContentEngineMalformedResponses::test_api_returns_empty_text PASSED [ 13%]
tests/unit/test_content_engine.py::TestContentEngineMalformedResponses::test_api_returns_whitespace_only_text PASSED [ 14%]
tests/unit/test_content_engine.py::TestContentEngineNetworkFailures::test_connection_error_with_retry PASSED [ 14%]
tests/unit/test_content_engine.py::TestContentEngineNetworkFailures::test_timeout_error_with_retry PASSED [ 14%]
tests/unit/test_content_engine.py::TestContentEngineNetworkFailures::test_connection_error_exhausts_retries PASSED [ 15%]
tests/unit/test_content_engine.py::TestContentEngineNetworkFailures::test_authentication_error_no_retry PASSED [ 15%]
tests/unit/test_content_engine.py::TestContentEngineAPIKeyValidation::test_get_api_key_with_invalid_format_from_env PASSED [ 15%]
tests/unit/test_content_engine.py::TestContentEngineAPIKeyValidation::test_get_api_key_with_valid_format PASSED [ 16%]
tests/unit/test_content_engine.py::TestContentEngineIntegration::test_real_api_call SKIPPED [ 16%]
tests/unit/test_data_detective.py::TestDataProfiling::test_prepare_data_summary_basic PASSED [ 16%]
tests/unit/test_data_detective.py::TestDataProfiling::test_prepare_data_summary_with_sample PASSED [ 17%]
tests/unit/test_data_detective.py::TestDataProfiling::test_prepare_data_summary_handles_nulls PASSED [ 17%]
tests/unit/test_data_detective.py::TestQualityAssessment::test_assess_clean_data PASSED [ 17%]
tests/unit/test_data_detective.py::TestQualityAssessment::test_assess_missing_values PASSED [ 18%]
tests/unit/test_data_detective.py::TestQualityAssessment::test_assess_duplicates PASSED [ 18%]
tests/unit/test_data_detective.py::TestQualityAssessment::test_assess_outliers PASSED [ 18%]
tests/unit/test_data_detective.py::TestQualityAssessment::test_quality_actions_available PASSED [ 19%]
tests/unit/test_data_detective.py::TestQualityAssessment::test_quality_action_execution PASSED [ 19%]
tests/unit/test_data_detective.py::TestAIInsights::test_generate_insights_with_valid_key PASSED [ 19%]
tests/unit/test_data_detective.py::TestAIInsights::test_generate_insights_with_invalid_key PASSED [ 20%]
tests/unit/test_data_detective.py::TestAIInsights::test_generate_insights_handles_empty_response PASSED [ 20%]
tests/unit/test_data_detective.py::TestNaturalLanguageQueries::test_process_nlq_with_valid_query PASSED [ 20%]
tests/unit/test_data_detective.py::TestNaturalLanguageQueries::test_process_nlq_with_error PASSED [ 21%]
tests/unit/test_data_detective.py::TestModuleImports::test_module_imports_successfully PASSED [ 21%]
tests/unit/test_data_detective.py::TestModuleImports::test_render_function_exists PASSED [ 21%]
tests/unit/test_data_detective.py::TestModuleImports::test_required_functions_exist PASSED [ 22%]
tests/unit/test_data_detective.py::TestConstants::test_constants_defined PASSED [ 22%]
tests/unit/test_data_detective.py::TestConstants::test_anthropic_available_flag PASSED [ 22%]
tests/unit/test_data_detective.py::TestEdgeCases::test_empty_dataframe PASSED [ 23%]
tests/unit/test_data_detective.py::TestEdgeCases::test_single_column_dataframe PASSED [ 23%]
tests/unit/test_data_detective.py::TestEdgeCases::test_all_null_column PASSED [ 23%]
tests/unit/test_data_detective.py::TestNewFeatures::test_correlation_matrix_calculated_correctly PASSED [ 24%]
tests/unit/test_data_detective.py::TestNewFeatures::test_correlation_with_multiple_numeric_columns PASSED [ 24%]
tests/unit/test_data_detective.py::TestNewFeatures::test_correlation_with_one_numeric_column PASSED [ 24%]
tests/unit/test_data_detective.py::TestNewFeatures::test_strong_correlation_detection FAILED [ 25%]
tests/unit/test_data_detective.py::TestNewFeatures::test_no_strong_correlations PASSED [ 25%]
tests/unit/test_data_detective.py::TestNewFeatures::test_correlation_with_all_zeros PASSED [ 25%]
tests/unit/test_data_detective.py::TestNewFeatures::test_perfect_correlation_detection PASSED [ 26%]
tests/unit/test_data_detective.py::TestNewFeatures::test_csv_file_reading PASSED [ 26%]
tests/unit/test_data_detective.py::TestNewFeatures::test_xlsx_file_reading_with_openpyxl PASSED [ 26%]
tests/unit/test_data_detective.py::TestNewFeatures::test_xls_file_reading FAILED [ 27%]
tests/unit/test_data_detective.py::TestNewFeatures::test_file_extension_detection_csv PASSED [ 27%]
tests/unit/test_data_detective.py::TestNewFeatures::test_file_extension_detection_xlsx PASSED [ 27%]
tests/unit/test_data_detective.py::TestNewFeatures::test_file_extension_detection_xls PASSED [ 28%]
tests/unit/test_data_detective.py::TestNewFeatures::test_file_extension_detection_uppercase PASSED [ 28%]
tests/unit/test_data_detective.py::TestNewFeatures::test_file_extension_detection_mixed_case PASSED [ 28%]
tests/unit/test_data_detective.py::TestNewFeatures::test_csv_vs_excel_data_equivalence PASSED [ 29%]
tests/unit/test_data_detective.py::TestNewFeatures::test_excel_file_with_multiple_sheets PASSED [ 29%]
tests/unit/test_data_detective.py::TestNewFeatures::test_excel_file_with_empty_cells PASSED [ 29%]
tests/unit/test_data_detective.py::TestNewFeatures::test_unsupported_file_extension PASSED [ 30%]
tests/unit/test_data_source_faker.py::test_generate_campaign_data_structure PASSED [ 30%]
tests/unit/test_data_source_faker.py::test_generate_campaign_data_platforms PASSED [ 30%]
tests/unit/test_data_source_faker.py::test_generate_campaign_data_date_range PASSED [ 31%]
tests/unit/test_data_source_faker.py::test_generate_campaign_data_values_plausibility PASSED [ 31%]
tests/unit/test_data_source_faker.py::test_generate_campaign_data_output_length PASSED [ 31%]
tests/unit/test_data_source_faker.py::test_generate_campaign_data_no_negative_values PASSED [ 32%]
tests/unit/test_design_system.py::TestDesignSystemModule::test_render_function_exists FAILED [ 32%]
tests/unit/test_design_system.py::TestDesignSystemModule::test_module_imports PASSED [ 32%]
tests/unit/test_design_system.py::TestDesignSystemModule::test_render_function_signature PASSED [ 33%]
tests/unit/test_design_system.py::TestColorPaletteRendering::test_render_color_palette_light_theme PASSED [ 33%]
tests/unit/test_design_system.py::TestColorPaletteRendering::test_render_color_palette_dark_theme PASSED [ 33%]
tests/unit/test_design_system.py::TestColorPaletteRendering::test_render_color_swatch PASSED [ 34%]
tests/unit/test_design_system.py::TestTabRenderFunctions::test_render_colors_tab FAILED [ 34%]
tests/unit/test_design_system.py::TestTabRenderFunctions::test_render_typography_tab PASSED [ 34%]
tests/unit/test_design_system.py::TestTabRenderFunctions::test_render_components_tab FAILED [ 35%]
tests/unit/test_design_system.py::TestTabRenderFunctions::test_render_interactive_tab FAILED [ 35%]
tests/unit/test_design_system.py::TestTabRenderFunctions::test_render_patterns_tab FAILED [ 35%]
tests/unit/test_design_system.py::TestColorSwatchLogic::test_color_swatch_text_contrast_light_theme PASSED [ 36%]
tests/unit/test_design_system.py::TestColorSwatchLogic::test_color_swatch_text_contrast_dark_theme PASSED [ 36%]
tests/unit/test_design_system.py::TestDesignSystemIntegration::test_imports_ui_components PASSED [ 36%]
tests/unit/test_design_system.py::TestDesignSystemIntegration::test_imports_ui_functions PASSED [ 37%]
tests/unit/test_design_system.py::TestDesignSystemDictStructure::test_light_theme_has_all_colors PASSED [ 37%]
tests/unit/test_design_system.py::TestDesignSystemDictStructure::test_dark_theme_has_all_colors PASSED [ 37%]
tests/unit/test_design_system.py::TestDesignSystemDictStructure::test_color_values_are_hex_codes PASSED [ 38%]
tests/unit/test_financial_analyst.py::TestFinancialAnalystRender::test_render_with_valid_ticker FAILED [ 38%]
tests/unit/test_financial_analyst.py::TestFinancialAnalystRender::test_render_with_empty_ticker PASSED [ 38%]
tests/unit/test_financial_analyst.py::TestFinancialAnalystRender::test_render_handles_data_fetch_error PASSED [ 39%]
tests/unit/test_financial_analyst.py::TestFinancialAnalystRender::test_render_handles_unexpected_exception PASSED [ 39%]
tests/unit/test_financial_analyst.py::TestFetchAndDisplayData::test_fetch_and_display_success PASSED [ 39%]
tests/unit/test_financial_analyst.py::TestFetchAndDisplayData::test_fetch_raises_error_on_no_info PASSED [ 40%]
tests/unit/test_financial_analyst.py::TestFetchAndDisplayData::test_fetch_raises_error_on_no_financials PASSED [ 40%]
tests/unit/test_financial_analyst.py::TestDisplayHeader::test_display_header_with_full_info PASSED [ 40%]
tests/unit/test_financial_analyst.py::TestDisplayHeader::test_display_header_without_summary PASSED [ 41%]
tests/unit/test_financial_analyst.py::TestDisplayKeyMetrics::test_display_key_metrics_with_valid_data PASSED [ 41%]
tests/unit/test_financial_analyst.py::TestDisplayKeyMetrics::test_display_key_metrics_with_missing_data PASSED [ 41%]
tests/unit/test_financial_analyst.py::TestFinancialAnalystEdgeCases::test_lowercase_ticker_converted_to_uppercase PASSED [ 42%]
tests/unit/test_financial_analyst.py::TestFinancialAnalystEdgeCases::test_market_cap_formatting PASSED [ 42%]
tests/unit/test_financial_analyst.py::TestFinancialAnalystEdgeCases::test_eps_formatting PASSED [ 42%]
tests/unit/test_financial_analyst.py::TestFinancialAnalystEdgeCases::test_pe_ratio_formatting PASSED [ 43%]
tests/unit/test_financial_analyst.py::TestAIInsights::test_display_ai_insights_enabled PASSED [ 43%]
tests/unit/test_financial_analyst.py::TestAIInsights::test_display_ai_insights_disabled PASSED [ 43%]
tests/unit/test_financial_analyst.py::TestAIInsights::test_build_financial_summary PASSED [ 44%]
tests/unit/test_financial_analyst.py::TestAIInsights::test_generate_financial_insights_success PASSED [ 44%]
tests/unit/test_financial_analyst.py::TestAIInsights::test_get_api_key_from_env PASSED [ 44%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_contribution_margin_calculation PASSED [ 45%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_contribution_margin_ratio_calculation PASSED [ 45%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_break_even_units_calculation PASSED [ 45%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_break_even_revenue_calculation PASSED [ 46%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_target_units_calculation PASSED [ 46%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_margin_of_safety_calculation PASSED [ 46%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_margin_of_safety_percentage PASSED [ 47%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_current_profit_calculation PASSED [ 47%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_operating_leverage_calculation PASSED [ 47%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_zero_contribution_margin_edge_case PASSED [ 48%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_high_fixed_costs_scenario PASSED [ 48%]
tests/unit/test_margin_hunter.py::TestMarginHunterCalculations::test_low_margin_high_volume_scenario PASSED [ 48%]
tests/unit/test_margin_hunter.py::TestMarginHunterRenderFunction::test_render_success_with_valid_inputs FAILED [ 49%]
tests/unit/test_margin_hunter.py::TestMarginHunterRenderFunction::test_render_error_when_price_equals_cost PASSED [ 49%]
tests/unit/test_margin_hunter.py::TestMarginHunterRenderFunction::test_render_calls_results_with_correct_params PASSED [ 49%]
tests/unit/test_margin_hunter.py::TestMarginHunterEdgeCases::test_zero_current_sales PASSED [ 50%]
tests/unit/test_margin_hunter.py::TestMarginHunterEdgeCases::test_negative_profit_scenario PASSED [ 50%]
tests/unit/test_margin_hunter.py::TestMarginHunterEdgeCases::test_very_small_contribution_margin PASSED [ 50%]
tests/unit/test_margin_hunter.py::TestMarginHunterEdgeCases::test_zero_fixed_costs PASSED [ 51%]
tests/unit/test_margin_hunter.py::TestMarginHunterEdgeCases::test_large_numbers PASSED [ 51%]
tests/unit/test_market_pulse.py::test_import_market_pulse PASSED         [ 51%]
tests/unit/test_market_pulse.py::TestMarketPulseRender::test_render_success_with_valid_ticker PASSED [ 52%]
tests/unit/test_market_pulse.py::TestMarketPulseRender::test_render_warning_on_empty_ticker PASSED [ 52%]
tests/unit/test_market_pulse.py::TestMarketPulseRender::test_render_error_on_no_data PASSED [ 52%]
tests/unit/test_market_pulse.py::TestMarketPulseRender::test_render_handles_invalid_ticker_error PASSED [ 53%]
tests/unit/test_market_pulse.py::TestMarketPulseRender::test_render_handles_data_fetch_error PASSED [ 53%]
tests/unit/test_market_pulse.py::TestDisplayMetrics::test_display_metrics_calculates_delta PASSED [ 53%]
tests/unit/test_market_pulse.py::TestCreateTechnicalChart::test_create_chart_returns_figure PASSED [ 54%]
tests/unit/test_market_pulse.py::TestCreateTechnicalChart::test_chart_has_four_panels PASSED [ 54%]
tests/unit/test_market_pulse.py::TestCreateTechnicalChart::test_chart_includes_candlestick_trace PASSED [ 54%]
tests/unit/test_market_pulse.py::TestCreateTechnicalChart::test_chart_includes_volume_bars PASSED [ 55%]
tests/unit/test_market_pulse.py::TestPredictiveIndicators::test_predict_trend_bullish PASSED [ 55%]
tests/unit/test_market_pulse.py::TestPredictiveIndicators::test_predict_trend_bearish PASSED [ 55%]
tests/unit/test_market_pulse.py::TestPredictiveIndicators::test_predict_trend_neutral PASSED [ 56%]
tests/unit/test_market_pulse.py::TestPredictiveIndicators::test_calculate_support_resistance PASSED [ 56%]
tests/unit/test_market_pulse.py::TestPredictiveIndicators::test_display_predictive_indicators PASSED [ 56%]
tests/unit/test_market_pulse.py::TestPredictiveIndicators::test_display_predictive_indicators_error_handling PASSED [ 57%]
tests/unit/test_market_pulse.py::TestPredictiveIndicators::test_predict_trend_reasoning_includes_indicators PASSED [ 57%]
tests/unit/test_marketing_analytics.py::TestROICalculations::test_roi_profitable_campaign PASSED [ 57%]
tests/unit/test_marketing_analytics.py::TestROICalculations::test_roi_unprofitable_campaign PASSED [ 58%]
tests/unit/test_marketing_analytics.py::TestROICalculations::test_roi_breakeven_campaign PASSED [ 58%]
tests/unit/test_marketing_analytics.py::TestROICalculations::test_roas_calculation PASSED [ 58%]
tests/unit/test_marketing_analytics.py::TestROICalculations::test_cpa_calculation PASSED [ 59%]
tests/unit/test_marketing_analytics.py::TestROICalculations::test_zero_spend_edge_case PASSED [ 59%]
tests/unit/test_marketing_analytics.py::TestROICalculations::test_zero_customers_edge_case PASSED [ 59%]
tests/unit/test_marketing_analytics.py::TestCustomerMetrics::test_cac_calculation PASSED [ 60%]
tests/unit/test_marketing_analytics.py::TestCustomerMetrics::test_clv_calculation PASSED [ 60%]
tests/unit/test_marketing_analytics.py::TestCustomerMetrics::test_clv_cac_ratio_healthy PASSED [ 60%]
tests/unit/test_marketing_analytics.py::TestCustomerMetrics::test_clv_cac_ratio_acceptable PASSED [ 61%]
tests/unit/test_marketing_analytics.py::TestCustomerMetrics::test_clv_cac_ratio_poor PASSED [ 61%]
tests/unit/test_marketing_analytics.py::TestABTestSignificance::test_ab_test_significant_win PASSED [ 61%]
tests/unit/test_marketing_analytics.py::TestABTestSignificance::test_ab_test_significant_loss PASSED [ 62%]
tests/unit/test_marketing_analytics.py::TestABTestSignificance::test_ab_test_not_significant PASSED [ 62%]
tests/unit/test_marketing_analytics.py::TestABTestSignificance::test_ab_test_small_sample_size PASSED [ 62%]
tests/unit/test_marketing_analytics.py::TestABTestSignificance::test_ab_test_zero_conversions PASSED [ 63%]
tests/unit/test_marketing_analytics.py::TestABTestSignificance::test_required_sample_size_calculation PASSED [ 63%]
tests/unit/test_marketing_analytics.py::TestAttributionModeling::test_first_touch_attribution PASSED [ 63%]
tests/unit/test_marketing_analytics.py::TestAttributionModeling::test_last_touch_attribution PASSED [ 64%]
tests/unit/test_marketing_analytics.py::TestAttributionModeling::test_linear_attribution PASSED [ 64%]
tests/unit/test_marketing_analytics.py::TestAttributionModeling::test_time_decay_attribution PASSED [ 64%]
tests/unit/test_marketing_analytics.py::TestAttributionModeling::test_attribution_all_models_sum_to_one PASSED [ 65%]
tests/unit/test_marketing_analytics.py::TestDataGeneration::test_generate_campaign_data PASSED [ 65%]
tests/unit/test_marketing_analytics.py::TestDataGeneration::test_generate_channel_breakdown PASSED [ 65%]
tests/unit/test_marketing_analytics.py::TestDataGeneration::test_generate_trend_data PASSED [ 66%]
tests/unit/test_marketing_analytics.py::TestDataGeneration::test_generate_cohort_data PASSED [ 66%]
tests/unit/test_marketing_analytics.py::TestDataGeneration::test_generate_journey_data PASSED [ 66%]
tests/unit/test_marketing_analytics.py::TestReportGeneration::test_generate_campaign_performance_report PASSED [ 67%]
tests/unit/test_marketing_analytics.py::TestReportGeneration::test_generate_customer_metrics_report PASSED [ 67%]
tests/unit/test_marketing_analytics.py::TestReportGeneration::test_generate_ab_test_report PASSED [ 67%]
tests/unit/test_marketing_analytics.py::TestReportGeneration::test_generate_attribution_report PASSED [ 68%]
tests/unit/test_marketing_analytics.py::TestModuleImports::test_module_imports_successfully PASSED [ 68%]
tests/unit/test_marketing_analytics.py::TestModuleImports::test_render_function_exists PASSED [ 68%]
tests/unit/test_marketing_analytics.py::TestModuleImports::test_required_functions_exist PASSED [ 69%]
tests/unit/test_marketing_analytics.py::TestConstants::test_constants_defined PASSED [ 69%]
tests/unit/test_marketing_analytics.py::TestConstants::test_attribution_models_list PASSED [ 69%]
tests/unit/test_marketing_analytics.py::TestEdgeCases::test_calculate_channel_metrics_all_channels PASSED [ 70%]
tests/unit/test_marketing_analytics.py::TestEdgeCases::test_calculate_channel_metrics_specific_channel PASSED [ 70%]
tests/unit/test_marketing_analytics.py::TestEdgeCases::test_ab_test_with_100_percent_conversion PASSED [ 70%]
tests/unit/test_marketing_analytics.py::TestEdgeCases::test_attribution_single_touchpoint PASSED [ 71%]
tests/unit/test_marketing_analytics.py::TestEdgeCases::test_empty_campaign_data_handling PASSED [ 71%]
tests/unit/test_marketing_analytics.py::TestEdgeCases::test_zero_variance_ab_test PASSED [ 71%]
tests/unit/test_marketing_analytics.py::TestMultiVariantTesting::test_multivariant_three_variants PASSED [ 72%]
tests/unit/test_marketing_analytics.py::TestMultiVariantTesting::test_multivariant_five_variants PASSED [ 72%]
tests/unit/test_marketing_analytics.py::TestMultiVariantTesting::test_multivariant_ten_variants PASSED [ 72%]
tests/unit/test_marketing_analytics.py::TestMultiVariantTesting::test_multivariant_significant_difference PASSED [ 73%]
tests/unit/test_marketing_analytics.py::TestMultiVariantTesting::test_multivariant_no_significant_difference PASSED [ 73%]
tests/unit/test_marketing_analytics.py::TestMultiVariantTesting::test_multivariant_best_variant_identification PASSED [ 73%]
tests/unit/test_marketing_analytics.py::TestMultiVariantTesting::test_multivariant_all_same_conversion_rates PASSED [ 74%]
tests/unit/test_marketing_analytics.py::TestMultiVariantTesting::test_multivariant_one_dominant_winner PASSED [ 74%]
tests/unit/test_marketing_analytics.py::TestMultiVariantTesting::test_multivariant_chi_square_statistic PASSED [ 74%]
tests/unit/test_marketing_analytics.py::TestMultiVariantTesting::test_multivariant_degrees_of_freedom PASSED [ 75%]
tests/unit/test_marketing_analytics.py::TestPositionBasedAttribution::test_position_based_single_touchpoint PASSED [ 75%]
tests/unit/test_marketing_analytics.py::TestPositionBasedAttribution::test_position_based_two_touchpoints PASSED [ 75%]
tests/unit/test_marketing_analytics.py::TestPositionBasedAttribution::test_position_based_three_touchpoints PASSED [ 76%]
tests/unit/test_marketing_analytics.py::TestPositionBasedAttribution::test_position_based_five_touchpoints PASSED [ 76%]
tests/unit/test_marketing_analytics.py::TestPositionBasedAttribution::test_position_based_credits_sum_to_one PASSED [ 76%]
tests/unit/test_marketing_analytics.py::TestPositionBasedAttribution::test_position_based_four_touchpoints PASSED [ 77%]
tests/unit/test_marketing_analytics.py::TestPositionBasedAttribution::test_position_based_duplicate_channels PASSED [ 77%]
tests/unit/test_marketing_analytics.py::TestPositionBasedAttribution::test_position_based_vs_other_models PASSED [ 77%]
tests/unit/test_marketing_analytics_data_integration.py::test_get_campaign_data_source_upload_csv PASSED [ 78%]
tests/unit/test_marketing_analytics_data_integration.py::test_get_campaign_data_source_upload_excel PASSED [ 78%]
tests/unit/test_marketing_analytics_data_integration.py::test_get_campaign_data_source_simulate_new_data PASSED [ 78%]
tests/unit/test_marketing_analytics_data_integration.py::test_get_campaign_data_source_simulate_existing_data FAILED [ 79%]
tests/unit/test_marketing_analytics_data_integration.py::test_render_campaign_dashboard_with_data FAILED [ 79%]
tests/unit/test_marketing_analytics_data_integration.py::test_render_campaign_dashboard_no_data PASSED [ 79%]
tests/unit/test_marketing_analytics_data_integration.py::test_calculate_channel_metrics PASSED [ 80%]
tests/unit/test_marketing_analytics_data_integration.py::test_get_channel_breakdown PASSED [ 80%]
tests/unit/test_smart_forecast.py::test_prepare_features PASSED          [ 80%]
tests/unit/test_smart_forecast.py::test_train_and_predict PASSED         [ 81%]
tests/unit/test_smart_forecast.py::test_render_flow PASSED               [ 81%]
tests/unit/test_ui.py::TestSetupInterface::test_setup_interface_injects_css PASSED [ 81%]
tests/unit/test_ui.py::TestSetupInterface::test_setup_interface_includes_theme_colors PASSED [ 82%]
tests/unit/test_ui.py::TestCardMetric::test_card_metric_with_all_params PASSED [ 82%]
tests/unit/test_ui.py::TestCardMetric::test_card_metric_without_optional_params PASSED [ 82%]
tests/unit/test_ui.py::TestSectionHeader::test_section_header_with_subtitle PASSED [ 83%]
tests/unit/test_ui.py::TestSectionHeader::test_section_header_without_subtitle PASSED [ 83%]
tests/unit/test_ui.py::TestStatusBadge::test_status_badge_active PASSED  [ 83%]
tests/unit/test_ui.py::TestStatusBadge::test_status_badge_new PASSED     [ 84%]
tests/unit/test_ui.py::TestStatusBadge::test_status_badge_hero PASSED    [ 84%]
tests/unit/test_ui.py::TestStatusBadge::test_status_badge_pending PASSED [ 84%]
tests/unit/test_ui.py::TestStatusBadge::test_status_badge_unknown_defaults_to_pending PASSED [ 85%]
tests/unit/test_ui.py::TestStatusBadge::test_status_badge_case_insensitive PASSED [ 85%]
tests/unit/test_ui.py::TestFeatureCard::test_feature_card_with_default_status PASSED [ 85%]
tests/unit/test_ui.py::TestFeatureCard::test_feature_card_with_custom_status PASSED [ 86%]
tests/unit/test_ui.py::TestFeatureCard::test_feature_card_has_accessibility_attributes PASSED [ 86%]
tests/unit/test_ui.py::TestHeroSection::test_hero_section_renders_title_and_subtitle PASSED [ 86%]
tests/unit/test_ui.py::TestHeroSection::test_hero_section_has_semantic_html PASSED [ 87%]
tests/unit/test_ui.py::TestUseCaseCard::test_use_case_card_renders_content PASSED [ 87%]
tests/unit/test_ui.py::TestUseCaseCard::test_use_case_card_has_accessibility PASSED [ 87%]
tests/unit/test_ui.py::TestComparisonTable::test_comparison_table_renders PASSED [ 88%]
tests/unit/test_ui.py::TestComparisonTable::test_comparison_table_has_all_columns PASSED [ 88%]
tests/unit/test_ui.py::TestComparisonTable::test_comparison_table_has_accessibility PASSED [ 88%]
tests/unit/test_ui.py::TestComparisonTable::test_comparison_table_has_comparison_rows PASSED [ 89%]
tests/unit/test_ui.py::TestFooter::test_footer_renders_copyright PASSED  [ 89%]
tests/unit/test_ui.py::TestFooter::test_footer_has_links PASSED          [ 89%]
tests/unit/test_ui.py::TestFooter::test_footer_has_semantic_html PASSED  [ 90%]
tests/unit/test_ui.py::TestFooter::test_footer_links_have_security_attributes PASSED [ 90%]
tests/unit/test_ui.py::TestThemeConstants::test_theme_has_all_colors PASSED [ 90%]
tests/unit/test_ui.py::TestThemeConstants::test_theme_has_font_family PASSED [ 91%]
tests/unit/test_ui.py::TestThemeConstants::test_theme_colors_are_valid_hex PASSED [ 91%]
tests/unit/test_ui.py::TestResponsiveDesign::test_css_has_mobile_breakpoints PASSED [ 91%]
tests/unit/test_ui.py::TestResponsiveDesign::test_css_has_focus_states PASSED [ 92%]
tests/unit/test_ui.py::TestSkeletonLoader::test_skeleton_loader_card_type PASSED [ 92%]
tests/unit/test_ui.py::TestSkeletonLoader::test_skeleton_loader_text_type PASSED [ 92%]
tests/unit/test_ui.py::TestSkeletonLoader::test_skeleton_loader_metric_type PASSED [ 93%]
tests/unit/test_ui.py::TestSkeletonLoader::test_skeleton_loader_table_type PASSED [ 93%]
tests/unit/test_ui.py::TestSkeletonLoader::test_skeleton_loader_multiple_count PASSED [ 93%]
tests/unit/test_ui.py::TestSkeletonLoader::test_skeleton_loader_default_count PASSED [ 94%]
tests/unit/test_ui.py::TestSkeletonLoader::test_skeleton_loader_invalid_type_defaults_to_card PASSED [ 94%]
tests/unit/test_ui.py::TestSkeletonLoader::test_skeleton_loader_has_accessibility_attributes PASSED [ 94%]
tests/unit/test_ui.py::TestToast::test_toast_uses_native_streamlit_when_available PASSED [ 95%]
tests/unit/test_ui.py::TestToast::test_toast_fallback_success PASSED     [ 95%]
tests/unit/test_ui.py::TestToast::test_toast_fallback_error PASSED       [ 95%]
tests/unit/test_ui.py::TestToast::test_toast_fallback_warning PASSED     [ 96%]
tests/unit/test_ui.py::TestToast::test_toast_fallback_info PASSED        [ 96%]
tests/unit/test_ui.py::TestToast::test_toast_custom_duration PASSED      [ 96%]
tests/unit/test_ui.py::TestToast::test_toast_default_duration PASSED     [ 97%]
tests/unit/test_ui.py::TestToast::test_toast_has_accessibility_attributes PASSED [ 97%]
tests/unit/test_ui.py::TestToast::test_toast_includes_auto_dismiss_script PASSED [ 97%]
tests/unit/test_ui.py::TestAnimations::test_css_has_shimmer_animation PASSED [ 98%]
tests/unit/test_ui.py::TestAnimations::test_css_has_fade_in_animation PASSED [ 98%]
tests/unit/test_ui.py::TestAnimations::test_css_has_bounce_animation PASSED [ 98%]
tests/unit/test_ui.py::TestAnimations::test_css_has_slide_animations PASSED [ 99%]
tests/unit/test_ui.py::TestAnimations::test_css_has_stagger_effect PASSED [ 99%]
tests/unit/test_ui.py::TestAnimations::test_css_respects_reduced_motion PASSED [ 99%]
tests/unit/test_ui.py::TestAnimations::test_css_has_smooth_transitions PASSED [100%]

=================================== FAILURES ===================================
_______________________ test_render_successful_analysis ________________________

mock_go = <MagicMock name='go' id='4817038240'>
mock_process = <MagicMock name='process_news_sentiment' id='4817038912'>
mock_get_news = <MagicMock name='get_news' id='4817039248'>
mock_st = <MagicMock name='st' id='4817039584'>

    @patch("modules.agent_logic.st")
    @patch("modules.agent_logic.get_news")
    @patch("modules.agent_logic.process_news_sentiment")
    @patch("modules.agent_logic.go")
    def test_render_successful_analysis(mock_go, mock_process, mock_get_news, mock_st):
        """Test the successful rendering path of the Agent Logic module."""
        # --- Arrange ---
        # Mock streamlit inputs
        mock_st.text_input.return_value = "AAPL"

        # Mock backend functions
        mock_get_news.return_value = MOCK_NEWS_ITEMS
        mock_process.return_value = MOCK_ANALYSIS

        # Mock the Figure object
        mock_figure = MagicMock()
        mock_go.Figure.return_value = mock_figure

        # --- Act ---
>       agent_logic.render()

tests/unit/test_agent_logic.py:56:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def render() -> None:
        """Render the Agent Logic (Sentiment Scout) module."""
        ui.section_header(
            "Agent Logic: Sentiment Scout", "AI-Powered Market Sentiment Analysis"
        )

        # Input
>       col1, col2 = st.columns([1, 3])
E       ValueError: not enough values to unpack (expected 2, got 0)

modules/agent_logic.py:34: ValueError
----------------------------- Captured stderr call -----------------------------
2025-12-22 11:09:25.157
  [33m[1mWarning:[0m to view this Streamlit app on a browser, run it with the following
  command:

    streamlit run /Library/Frameworks/Python.framework/Versions/3.13/bin/pytest [ARGUMENTS]
__________________________ test_render_no_news_found ___________________________

mock_process = <MagicMock name='process_news_sentiment' id='4818914336'>
mock_get_news = <MagicMock name='get_news' id='4818914672'>
mock_st = <MagicMock name='st' id='4818915008'>

    @patch("modules.agent_logic.st")
    @patch("modules.agent_logic.get_news")
    @patch("modules.agent_logic.process_news_sentiment")
    def test_render_no_news_found(mock_process, mock_get_news, mock_st):
        """Test the case where no news is found for a ticker."""
        # --- Arrange ---
        mock_st.text_input.return_value = "FAILTICKER"
        mock_get_news.return_value = []  # No news

        # --- Act ---
>       agent_logic.render()

tests/unit/test_agent_logic.py:88:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def render() -> None:
        """Render the Agent Logic (Sentiment Scout) module."""
        ui.section_header(
            "Agent Logic: Sentiment Scout", "AI-Powered Market Sentiment Analysis"
        )

        # Input
>       col1, col2 = st.columns([1, 3])
E       ValueError: not enough values to unpack (expected 2, got 0)

modules/agent_logic.py:34: ValueError
________________________ test_render_no_ticker_entered _________________________

mock_get_news = <MagicMock name='get_news' id='4818916688'>
mock_st = <MagicMock name='st' id='4818917024'>

    @patch("modules.agent_logic.st")
    @patch("modules.agent_logic.get_news")
    def test_render_no_ticker_entered(mock_get_news, mock_st):
        """Test the case where no ticker is entered."""
        # --- Arrange ---
        mock_st.text_input.return_value = ""  # Empty input

        # --- Act ---
>       agent_logic.render()

tests/unit/test_agent_logic.py:108:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def render() -> None:
        """Render the Agent Logic (Sentiment Scout) module."""
        ui.section_header(
            "Agent Logic: Sentiment Scout", "AI-Powered Market Sentiment Analysis"
        )

        # Input
>       col1, col2 = st.columns([1, 3])
E       ValueError: not enough values to unpack (expected 2, got 0)

modules/agent_logic.py:34: ValueError
________________________ test_render_handles_exception _________________________

mock_get_news = <MagicMock name='get_news' id='4818918704'>
mock_st = <MagicMock name='st' id='4818919040'>

    @patch("modules.agent_logic.st")
    @patch("modules.agent_logic.get_news")
    def test_render_handles_exception(mock_get_news, mock_st):
        """Test that errors during data fetching are handled gracefully."""
        # --- Arrange ---
        mock_st.text_input.return_value = "AAPL"
        mock_get_news.side_effect = Exception("Network Error")

        # --- Act ---
>       agent_logic.render()

tests/unit/test_agent_logic.py:126:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def render() -> None:
        """Render the Agent Logic (Sentiment Scout) module."""
        ui.section_header(
            "Agent Logic: Sentiment Scout", "AI-Powered Market Sentiment Analysis"
        )

        # Input
>       col1, col2 = st.columns([1, 3])
E       ValueError: not enough values to unpack (expected 2, got 0)

modules/agent_logic.py:34: ValueError
______________ TestNewFeatures.test_strong_correlation_detection _______________

self = <tests.unit.test_data_detective.TestNewFeatures object at 0x11e9eba80>
df_strong_correlation =    col1  col2  col3
0     1     2     5
1     2     4     4
2     3     6     3
3     4     8     2
4     5    10     1

    def test_strong_correlation_detection(self, df_strong_correlation):
        """Test detection of strong correlations (|r| >= 0.7)."""
        numeric_cols = df_strong_correlation.select_dtypes(include=[np.number]).columns.tolist()
        corr_matrix = df_strong_correlation[numeric_cols].corr()

        # Find strong correlations
        strong_corrs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i + 1, len(corr_matrix.columns)):
                corr_value = corr_matrix.iloc[i, j]
                if abs(corr_value) >= 0.7:
                    strong_corrs.append(
                        {
                            "col1": corr_matrix.columns[i],
                            "col2": corr_matrix.columns[j],
                            "correlation": corr_value,
                        }
                    )

        # Should find 2 strong correlations
>       assert len(strong_corrs) == 2
E       AssertionError: assert 3 == 2
E        +  where 3 = len([{'col1': 'col1', 'col2': 'col2', 'correlation': 1.0}, {'col1': 'col1', 'col2': 'col3', 'correlation': -1.0}, {'col1': 'col2', 'col2': 'col3', 'correlation': -1.0}])

tests/unit/test_data_detective.py:544: AssertionError
____________________ TestNewFeatures.test_xls_file_reading _____________________

engine_name = 'xlwt'

    def get_writer(engine_name: str) -> ExcelWriter_t:
        try:
>           return _writers[engine_name]
E           KeyError: 'xlwt'

/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/excel/_util.py:93: KeyError

The above exception was the direct cause of the following exception:

self = <tests.unit.test_data_detective.TestNewFeatures object at 0x11e94f6b0>
sample_excel_data =    col1 col2  col3
0     1    A  10.5
1     2    B  20.3
2     3    C  30.1
3     4    D  40.7
4     5    E  50.9
tmp_path = PosixPath('/private/var/folders/dk/rtn6hxh950v317cq3xxz76r00000gq/T/pytest-of-Cave/pytest-13/test_xls_file_reading0')

    def test_xls_file_reading(self, sample_excel_data, tmp_path):
        """Test that .xls files are read correctly."""
        # Create temporary .xls file (using xlwt if available, otherwise skip)
        try:
            xls_path = tmp_path / "test_file.xls"
>           sample_excel_data.to_excel(xls_path, index=False, engine="xlwt")

tests/unit/test_data_detective.py:667:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/util/_decorators.py:333: in wrapper
    return func(*args, **kwargs)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py:2439: in to_excel
    formatter.write(
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/formats/excel.py:943: in write
    writer = ExcelWriter(
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/excel/_base.py:1146: in __new__
    cls = get_writer(engine)  # type: ignore[assignment]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

engine_name = 'xlwt'

    def get_writer(engine_name: str) -> ExcelWriter_t:
        try:
            return _writers[engine_name]
        except KeyError as err:
>           raise ValueError(f"No Excel writer '{engine_name}'") from err
E           ValueError: No Excel writer 'xlwt'

/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/excel/_util.py:95: ValueError
______________ TestDesignSystemModule.test_render_function_exists ______________

self = <MagicMock name='tabs' id='4827429392'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'tabs' to have been called once. Called 2 times.
E           Calls: [call(['üé® Colors', 'üìù Typography', 'üß© Components', 'üéØ Interactive Elements', 'üìã Patterns']),
E            call(['Overview', 'Details', 'Settings'])].

/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:956: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.unit.test_design_system.TestDesignSystemModule object at 0x11ea8a710>
mock_tabs = <MagicMock name='tabs' id='4827429392'>
mock_markdown = <MagicMock name='markdown' id='4827428048'>
mock_title = <MagicMock name='title' id='4827427712'>

    @patch("streamlit.title")
    @patch("streamlit.markdown")
    @patch("streamlit.tabs")
    def test_render_function_exists(self, mock_tabs, mock_markdown, mock_title):
        """Verify render() function exists and is callable."""
        from modules.design_system import render

        # Mock tabs to return a list of mock contexts
        mock_tab_contexts = [MagicMock() for _ in range(5)]
        mock_tabs.return_value = mock_tab_contexts

        # Mock __enter__ and __exit__ for context managers
        for ctx in mock_tab_contexts:
            ctx.__enter__ = MagicMock(return_value=ctx)
            ctx.__exit__ = MagicMock(return_value=False)

        render()

        # Verify title was called
        mock_title.assert_called_once_with("Design System Gallery")

        # Verify tabs were created with correct labels
>       mock_tabs.assert_called_once()
E       AssertionError: Expected 'tabs' to have been called once. Called 2 times.
E       Calls: [call(['üé® Colors', 'üìù Typography', 'üß© Components', 'üéØ Interactive Elements', 'üìã Patterns']),
E        call(['Overview', 'Details', 'Settings'])].
E
E       pytest introspection follows:
E
E       Args:
E       assert (['Overview', 'Details', 'Settings'],) == ()
E         Left contains one more item: ['Overview', 'Details', 'Settings']
E         Full diff:
E         - ()
E         + (['Overview', 'Details', 'Settings'],)

tests/unit/test_design_system.py:39: AssertionError
________________ TestTabRenderFunctions.test_render_colors_tab _________________

self = <tests.unit.test_design_system.TestTabRenderFunctions object at 0x11ea8ad50>
mock_code = <MagicMock name='code' id='4827417632'>
mock_columns = <MagicMock name='columns' id='4827416288'>
mock_markdown = <MagicMock name='markdown' id='4827419648'>

    @patch("streamlit.markdown")
    @patch("streamlit.columns")
    @patch("streamlit.code")
    def test_render_colors_tab(self, mock_code, mock_columns, mock_markdown):
        """Test colors tab rendering."""
        from modules.design_system import _render_colors_tab

        # Mock columns
        mock_col = MagicMock()
        mock_col.__enter__ = MagicMock(return_value=mock_col)
        mock_col.__exit__ = MagicMock(return_value=False)
        mock_columns.return_value = [mock_col] * 5

>       _render_colors_tab()

tests/unit/test_design_system.py:142:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def _render_colors_tab() -> None:
        """Render the color palette showcase."""
        st.markdown("## Color System")
        st.markdown(
            "All colors meet WCAG AAA compliance standards (7:1+ contrast ratio) for optimal accessibility."
        )

        # Light Theme
        st.markdown("---")
        st.markdown("### ‚òÄÔ∏è Light Theme")

        light_colors = ui.LIGHT_THEME
        _render_color_palette(light_colors, "light")

        # Dark Theme
        st.markdown("---")
        st.markdown("### üåô Dark Theme")

        dark_colors = ui.DARK_THEME
        _render_color_palette(dark_colors, "dark")

        # Color Usage Guide
        st.markdown("---")
        st.markdown("### üìñ Color Usage Guide")

>       col1, col2 = st.columns(2)
E       ValueError: too many values to unpack (expected 2)

modules/design_system.py:78: ValueError
______________ TestTabRenderFunctions.test_render_components_tab _______________

self = <tests.unit.test_design_system.TestTabRenderFunctions object at 0x11e9ebe10>
mock_comparison = <MagicMock name='comparison_table' id='4828173312'>
mock_header = <MagicMock name='section_header' id='4828173648'>
mock_badge = <MagicMock name='status_badge' id='4828173984'>
mock_use_case = <MagicMock name='use_case_card' id='4828174320'>
mock_feature = <MagicMock name='feature_card' id='4828174656'>
mock_hero = <MagicMock name='hero_section' id='4828174992'>
mock_expander = <MagicMock name='expander' id='4828175328'>
mock_columns = <MagicMock name='columns' id='4828175664'>
mock_markdown = <MagicMock name='markdown' id='4828176000'>

    @patch("streamlit.markdown")
    @patch("streamlit.columns")
    @patch("streamlit.expander")
    @patch("utils.ui.hero_section")
    @patch("utils.ui.feature_card")
    @patch("utils.ui.use_case_card")
    @patch("utils.ui.status_badge")
    @patch("utils.ui.section_header")
    @patch("utils.ui.comparison_table")
    def test_render_components_tab(
        self,
        mock_comparison,
        mock_header,
        mock_badge,
        mock_use_case,
        mock_feature,
        mock_hero,
        mock_expander,
        mock_columns,
        mock_markdown,
    ):
        """Test components tab rendering."""
        from modules.design_system import _render_components_tab

        # Mock columns
        mock_col = MagicMock()
        mock_col.__enter__ = MagicMock(return_value=mock_col)
        mock_col.__exit__ = MagicMock(return_value=False)
        mock_columns.return_value = [mock_col] * 4

        # Mock expander context
        mock_exp_ctx = MagicMock()
        mock_exp_ctx.__enter__ = MagicMock(return_value=mock_exp_ctx)
        mock_exp_ctx.__exit__ = MagicMock(return_value=False)
        mock_expander.return_value = mock_exp_ctx

        # Mock status_badge to return HTML
        mock_badge.return_value = "<span>badge</span>"

>       _render_components_tab()

tests/unit/test_design_system.py:204:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def _render_components_tab() -> None:
        """Render the components showcase."""
        st.markdown("## Component Library")
        st.markdown("Pre-built components with consistent styling and behavior.")

        # Hero Section
        st.markdown("---")
        st.markdown("### Hero Section")
        st.markdown("**Usage:** Landing pages, module introductions")

        ui.hero_section(
            "Welcome to Enterprise Hub",
            "A production-grade business intelligence platform with 7 mission-critical tools in one unified interface.",
        )

        with st.expander("View Code"):
            st.code(
                """
    ui.hero_section(
        "Welcome to Enterprise Hub",
        "A production-grade business intelligence platform..."
    )
            """,
                language="python",
            )

        # Feature Cards
        st.markdown("---")
        st.markdown("### Feature Cards")
        st.markdown("**Usage:** Module showcases, feature highlights")

>       col1, col2, col3 = st.columns(3)
E       ValueError: too many values to unpack (expected 3)

modules/design_system.py:352: ValueError
______________ TestTabRenderFunctions.test_render_interactive_tab ______________

self = <tests.unit.test_design_system.TestTabRenderFunctions object at 0x11eac4050>
mock_metric = <MagicMock name='card_metric' id='4827428720'>
mock_expander = <MagicMock name='expander' id='4827419984'>
mock_button = <MagicMock name='button' id='4827428384'>
mock_columns = <MagicMock name='columns' id='4827421328'>
mock_markdown = <MagicMock name='markdown' id='4827419648'>

    @patch("streamlit.markdown")
    @patch("streamlit.columns")
    @patch("streamlit.button")
    @patch("streamlit.expander")
    @patch("utils.ui.card_metric")
    def test_render_interactive_tab(
        self, mock_metric, mock_expander, mock_button, mock_columns, mock_markdown
    ):
        """Test interactive elements tab rendering."""
        from modules.design_system import _render_interactive_tab

        # Mock columns
        mock_col = MagicMock()
        mock_col.__enter__ = MagicMock(return_value=mock_col)
        mock_col.__exit__ = MagicMock(return_value=False)
        mock_columns.return_value = [mock_col] * 4

        # Mock expander
        mock_exp_ctx = MagicMock()
        mock_exp_ctx.__enter__ = MagicMock(return_value=mock_exp_ctx)
        mock_exp_ctx.__exit__ = MagicMock(return_value=False)
        mock_expander.return_value = mock_exp_ctx

>       _render_interactive_tab()

tests/unit/test_design_system.py:236:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def _render_interactive_tab() -> None:
        """Render interactive elements showcase."""
        st.markdown("## Interactive Elements")
        st.markdown("Buttons, inputs, and interactive components with consistent styling.")

        # Buttons
        st.markdown("---")
        st.markdown("### Buttons")

>       col1, col2, col3 = st.columns(3)
E       ValueError: too many values to unpack (expected 3)

modules/design_system.py:505: ValueError
_______________ TestTabRenderFunctions.test_render_patterns_tab ________________

self = <tests.unit.test_design_system.TestTabRenderFunctions object at 0x11eab60f0>
mock_expander = <MagicMock name='expander' id='4827422336'>
mock_tabs = <MagicMock name='tabs' id='4827422672'>
mock_columns = <MagicMock name='columns' id='4827423008'>
mock_markdown = <MagicMock name='markdown' id='4827423344'>

    @patch("streamlit.markdown")
    @patch("streamlit.columns")
    @patch("streamlit.tabs")
    @patch("streamlit.expander")
    def test_render_patterns_tab(self, mock_expander, mock_tabs, mock_columns, mock_markdown):
        """Test patterns tab rendering."""
        from modules.design_system import _render_patterns_tab

        # Mock columns
        mock_col = MagicMock()
        mock_col.__enter__ = MagicMock(return_value=mock_col)
        mock_col.__exit__ = MagicMock(return_value=False)
        mock_columns.return_value = [mock_col] * 3

        # Mock expander
        mock_exp_ctx = MagicMock()
        mock_exp_ctx.__enter__ = MagicMock(return_value=mock_exp_ctx)
        mock_exp_ctx.__exit__ = MagicMock(return_value=False)
        mock_expander.return_value = mock_exp_ctx

        # Mock tabs
        mock_tab_ctx = MagicMock()
        mock_tab_ctx.__enter__ = MagicMock(return_value=mock_tab_ctx)
        mock_tab_ctx.__exit__ = MagicMock(return_value=False)
        mock_tabs.return_value = [mock_tab_ctx] * 3

>       _render_patterns_tab()

tests/unit/test_design_system.py:267:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def _render_patterns_tab() -> None:
        """Render common UI patterns and layouts."""
        st.markdown("## Common Patterns")
        st.markdown("Reusable layout patterns and composition examples.")

        # Column Layouts
        st.markdown("---")
        st.markdown("### Column Layouts")

        st.markdown("#### Two Column Layout (50/50)")
>       col1, col2 = st.columns(2)
E       ValueError: too many values to unpack (expected 2)

modules/design_system.py:647: ValueError
___________ TestFinancialAnalystRender.test_render_with_valid_ticker ___________

self = <MagicMock name='st.markdown' id='4828183056'>
args = ('## Financial Analyst',), kwargs = {}
expected = call('## Financial Analyst'), cause = None, actual = []
expected_string = "markdown('## Financial Analyst')"

    def assert_any_call(self, /, *args, **kwargs):
        """assert the mock has been called with the specified arguments.

        The assert passes if the mock has *ever* been called, unlike
        `assert_called_with` and `assert_called_once_with` that only pass if
        the call is the most recent one."""
        expected = self._call_matcher(_Call((args, kwargs), two=True))
        cause = expected if isinstance(expected, Exception) else None
        actual = [self._call_matcher(c) for c in self.call_args_list]
        if cause or expected not in _AnyComparer(actual):
            expected_string = self._format_mock_call_signature(args, kwargs)
>           raise AssertionError(
                '%s call not found' % expected_string
            ) from cause
E           AssertionError: markdown('## Financial Analyst') call not found

/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1048: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.unit.test_financial_analyst.TestFinancialAnalystRender object at 0x11ea8b890>
mock_fetch = <MagicMock name='_fetch_and_display_data' id='4828177680'>
mock_st = <MagicMock name='st' id='4828178016'>

    @patch("modules.financial_analyst.st")
    @patch("modules.financial_analyst._fetch_and_display_data")
    def test_render_with_valid_ticker(self, mock_fetch, mock_st):
        """Test successful render with valid ticker."""
        from modules import financial_analyst

        # Mock input
        mock_st.text_input.return_value = "AAPL"
        mock_st.columns.return_value = [MagicMock(), MagicMock()]

        # Call render
        financial_analyst.render()

        # Assertions
>       mock_st.markdown.assert_any_call("## Financial Analyst")
E       AssertionError: markdown('## Financial Analyst') call not found

tests/unit/test_financial_analyst.py:57: AssertionError
_____ TestMarginHunterRenderFunction.test_render_success_with_valid_inputs _____

self = <MagicMock name='section_header' id='4832202096'>
args = ('Margin Hunter', 'Break-Even & Profit Analysis'), kwargs = {}
expected = call('Margin Hunter', 'Break-Even & Profit Analysis')
actual = call('Margin Hunter', 'Profitability & Break-Even Analysis')
_error_message = <function NonCallableMock.assert_called_with.<locals>._error_message at 0x11fd0a520>
cause = None

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.

        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\n  Actual: %s'
                    % (expected, actual))
            raise AssertionError(error_message)

        def _error_message():
            msg = self._format_mock_failure_message(args, kwargs)
            return msg
        expected = self._call_matcher(_Call((args, kwargs), two=True))
        actual = self._call_matcher(self.call_args)
        if actual != expected:
            cause = expected if isinstance(expected, Exception) else None
>           raise AssertionError(_error_message()) from cause
E           AssertionError: expected call not found.
E           Expected: section_header('Margin Hunter', 'Break-Even & Profit Analysis')
E             Actual: section_header('Margin Hunter', 'Profitability & Break-Even Analysis')

/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:977: AssertionError

During handling of the above exception, another exception occurred:

self = <MagicMock name='section_header' id='4832202096'>
args = ('Margin Hunter', 'Break-Even & Profit Analysis'), kwargs = {}

    def assert_called_once_with(self, /, *args, **kwargs):
        """assert that the mock was called exactly once and that that call was
        with the specified arguments."""
        if not self.call_count == 1:
            msg = ("Expected '%s' to be called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
            raise AssertionError(msg)
>       return self.assert_called_with(*args, **kwargs)
E       AssertionError: expected call not found.
E       Expected: section_header('Margin Hunter', 'Break-Even & Profit Analysis')
E         Actual: section_header('Margin Hunter', 'Profitability & Break-Even Analysis')
E
E       pytest introspection follows:
E
E       Args:
E       assert ('Margin Hunter', 'Profitability & Break-Even Analysis') == ('Margin Hunter', 'Break-Even & Profit Analysis')
E         At index 1 diff: 'Profitability & Break-Even Analysis' != 'Break-Even & Profit Analysis'
E         Full diff:
E         - ('Margin Hunter', 'Break-Even & Profit Analysis')
E         ?                               ---------
E         + ('Margin Hunter', 'Profitability & Break-Even Analysis')
E         ?                    ++++++++++++++++

/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:989: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.unit.test_margin_hunter.TestMarginHunterRenderFunction object at 0x11eaf87d0>
mock_st = <MagicMock name='st' id='4832202768'>
mock_section = <MagicMock name='section_header' id='4832202096'>

    @patch("modules.margin_hunter.ui.section_header")
    @patch("modules.margin_hunter.st")
    def test_render_success_with_valid_inputs(self, mock_st, mock_section):
        """Test successful render with valid inputs."""
        from modules import margin_hunter

        # Mock Streamlit inputs
        mock_st.number_input.side_effect = [
            50.0,  # unit_price
            20.0,  # unit_cost
            5000.0,  # fixed_costs
            2000.0,  # target_profit
            250,  # current_sales_units
        ]

        # Mock columns
        mock_col1 = MagicMock()
        mock_col2 = MagicMock()
        mock_st.columns.return_value = [mock_col1, mock_col2]

        # Call render
        margin_hunter.render()

        # Assertions
>       mock_section.assert_called_once_with("Margin Hunter", "Break-Even & Profit Analysis")
E       AssertionError: expected call not found.
E       Expected: section_header('Margin Hunter', 'Break-Even & Profit Analysis')
E         Actual: section_header('Margin Hunter', 'Profitability & Break-Even Analysis')
E
E       pytest introspection follows:
E
E       Args:
E       assert ('Margin Hunter', 'Profitability & Break-Even Analysis') == ('Margin Hunter', 'Break-Even & Profit Analysis')
E         At index 1 diff: 'Profitability & Break-Even Analysis' != 'Break-Even & Profit Analysis'
E         Full diff:
E         - ('Margin Hunter', 'Break-Even & Profit Analysis')
E         ?                               ---------
E         + ('Margin Hunter', 'Profitability & Break-Even Analysis')
E         ?                    ++++++++++++++++

tests/unit/test_margin_hunter.py:129: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-12-22 11:09:29,962 - modules.margin_hunter - ERROR - An unexpected error occurred in Margin Hunter: not enough values to unpack (expected 3, got 2)
Traceback (most recent call last):
  File "/Users/Cave/Desktop/enterprise-hub/EnterpriseHub/modules/margin_hunter.py", line 79, in render
    _render_results(
    ~~~~~~~~~~~~~~~^
        contribution_margin,
        ^^^^^^^^^^^^^^^^^^^^
    ...<13 lines>...
        target_profit,
        ^^^^^^^^^^^^^^
    )
    ^
  File "/Users/Cave/Desktop/enterprise-hub/EnterpriseHub/modules/margin_hunter.py", line 127, in _render_results
    m1, m2, m3 = st.columns(3)
    ^^^^^^^^^^
ValueError: not enough values to unpack (expected 3, got 2)
------------------------------ Captured log call -------------------------------
ERROR    modules.margin_hunter:margin_hunter.py:98 An unexpected error occurred in Margin Hunter: not enough values to unpack (expected 3, got 2)
Traceback (most recent call last):
  File "/Users/Cave/Desktop/enterprise-hub/EnterpriseHub/modules/margin_hunter.py", line 79, in render
    _render_results(
    ~~~~~~~~~~~~~~~^
        contribution_margin,
        ^^^^^^^^^^^^^^^^^^^^
    ...<13 lines>...
        target_profit,
        ^^^^^^^^^^^^^^
    )
    ^
  File "/Users/Cave/Desktop/enterprise-hub/EnterpriseHub/modules/margin_hunter.py", line 127, in _render_results
    m1, m2, m3 = st.columns(3)
    ^^^^^^^^^^
ValueError: not enough values to unpack (expected 3, got 2)
_____________ test_get_campaign_data_source_simulate_existing_data _____________

self = <MagicMock name='st.selectbox' id='4847894944'>

    def assert_not_called(self):
        """assert that the mock was never called.
        """
        if self.call_count != 0:
            msg = ("Expected '%s' to not have been called. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'selectbox' to not have been called. Called 1 times.
E           Calls: [call('Simulate for Platform', ['Google Ads', 'Meta Ads'])].

/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:938: AssertionError

During handling of the above exception, another exception occurred:

mock_st = <MagicMock name='st' id='4848322944'>

    @patch("modules.marketing_analytics.st")
    def test_get_campaign_data_source_simulate_existing_data(mock_st):
        """Test _get_campaign_data_source when 'Simulate Marketing Data' is selected and existing data is used."""
        mock_st.radio.return_value = "Simulate Marketing Data"
        mock_st.button.return_value = False  # DO NOT generate new data
        # Pre-populate session state
        mock_st.session_state = {
            "simulated_campaign_data": generate_campaign_data(platform="Meta Ads", days=3)
        }

        # Configure mock_st.columns for this test
        mock_st.columns.return_value = [MagicMock(), MagicMock()]

        df = marketing_analytics._get_campaign_data_source()

        mock_st.radio.assert_called_once()
        # No calls to selectbox, date_input, slider, button if existing data is used
>       mock_st.selectbox.assert_not_called()
E       AssertionError: Expected 'selectbox' to not have been called. Called 1 times.
E       Calls: [call('Simulate for Platform', ['Google Ads', 'Meta Ads'])].
E
E       pytest introspection follows:
E
E       Args:
E       assert ('Simulate for Platform', ['Google Ads', 'Meta Ads']) == ()
E         Left contains 2 more items, first extra item: 'Simulate for Platform'
E         Full diff:
E         - ()
E         + ('Simulate for Platform', ['Google Ads', 'Meta Ads'])

tests/unit/test_marketing_analytics_data_integration.py:121: AssertionError
___________________ test_render_campaign_dashboard_with_data ___________________

self = <MagicMock name='ui.card_metric' id='4847905360'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'card_metric' to have been called.

/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:946: AssertionError

During handling of the above exception, another exception occurred:

mock_calc_metrics = <MagicMock name='_calculate_channel_metrics' id='4847898640'>
mock_get_data_source = <MagicMock name='_get_campaign_data_source' id='4847898976'>
mock_ui = <MagicMock name='ui' id='4847899312'>
mock_st = <MagicMock name='st' id='4847899648'>
sample_campaign_df =         Date    Platform  Impressions  ...     CTR  Conversion_Rate  ROAS
0 2023-01-01  Google Ads       101087  ...  ...         0.0208  1.81
9 2023-01-10  Google Ads        82167  ...  0.0098           0.0210  2.03

[10 rows x 11 columns]

    @patch("modules.marketing_analytics.st")
    @patch("modules.marketing_analytics.ui")
    @patch("modules.marketing_analytics._get_campaign_data_source")
    @patch("modules.marketing_analytics._calculate_channel_metrics")  # Patch the helper function
    def test_render_campaign_dashboard_with_data(
        mock_calc_metrics, mock_get_data_source, mock_ui, mock_st, sample_campaign_df
    ):
        """Test _render_campaign_dashboard renders correctly when data is available."""
        mock_get_data_source.return_value = sample_campaign_df
        mock_st.selectbox.return_value = "All Platforms"  # Mock platform filter
        mock_st.date_input.side_effect = [
            sample_campaign_df["Date"].min(),
            sample_campaign_df["Date"].max(),
        ]  # Mock date filters

        # Mock _calculate_channel_metrics to return a plausible dict
        mock_calc_metrics.return_value = {
            "spend": 10000,
            "revenue": 30000,
            "roi": 3.0,
            "conversions": 500,
            "spend_change": 10,
            "revenue_change": 15,
            "roi_change": 5,
            "conversion_change": 8,
        }

        # Mock st.columns
        mock_st.columns.side_effect = lambda num_cols: [MagicMock() for _ in range(num_cols)]

        # Mock the Plotly figure methods that are called
        mock_st.plotly_chart.return_value = None

        marketing_analytics._render_campaign_dashboard()

        mock_get_data_source.assert_called_once()
        mock_st.subheader.assert_any_call("üìà Campaign Performance Dashboard")
        mock_st.selectbox.assert_called_once()
        mock_st.date_input.assert_called()  # Twice for start and end
>       mock_ui.card_metric.assert_called()  # Should be called multiple times
E       AssertionError: Expected 'card_metric' to have been called.

tests/unit/test_marketing_analytics_data_integration.py:168: AssertionError
=============================== warnings summary ===============================
<frozen importlib._bootstrap>:488
  <frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.MessageMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.

<frozen importlib._bootstrap>:488
  <frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.ScalarMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.

tests/unit/test_data_detective.py: 12 warnings
  /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openpyxl/packaging/core.py:99: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    now = datetime.datetime.utcnow()

tests/unit/test_data_detective.py::TestNewFeatures::test_xlsx_file_reading_with_openpyxl
tests/unit/test_data_detective.py::TestNewFeatures::test_csv_vs_excel_data_equivalence
tests/unit/test_data_detective.py::TestNewFeatures::test_excel_file_with_multiple_sheets
tests/unit/test_data_detective.py::TestNewFeatures::test_excel_file_with_empty_cells
  /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openpyxl/writer/excel.py:292: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    workbook.properties.modified = datetime.datetime.utcnow()

tests/unit/test_smart_forecast.py: 30 warnings
  /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning:

  X does not have valid feature names, but RandomForestRegressor was fitted with feature names

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

---------- coverage: platform darwin, python 3.13.0-final-0 ----------
Name                             Stmts   Miss  Cover   Missing
--------------------------------------------------------------
app.py                             116    116     0%   8-332
modules/__init__.py                  0      0   100%
modules/agent_logic.py              75     40    47%   21-22, 50-51, 63-144, 154
modules/content_engine.py          247    110    55%   29-30, 160-161, 170-191, 223, 241-267, 288-445, 648
modules/data_detective.py          311    219    30%   32-33, 47-124, 129-281, 286-316, 321-369, 374-423, 428-464, 474-519, 613
modules/design_system.py           297      2    99%   510, 521
modules/financial_analyst.py       208     63    70%   19-20, 79-80, 138-190, 197-218, 223-247, 257, 285, 339-346
modules/margin_hunter.py            92     45    51%   128-166, 188-251, 258-287, 301-332
modules/market_pulse.py            156     20    87%   83-91, 113-115, 149-154, 268-272
modules/marketing_analytics.py     593    379    36%   34-61, 103-252, 257-472, 477-602, 607-725, 730-745, 750-870, 877-1041, 1070-1133, 1138-1186, 1221-1222, 1254, 1278, 1309, 1570-1571, 1587, 1600-1601, 1606, 1616, 1649-1650
modules/multi_agent.py              97     97     0%   8-196
modules/smart_forecast.py           86      5    94%   39-40, 52-54
utils/data_loader.py                86     60    30%   49-83, 113-150, 169-179, 193-207, 222
utils/data_source_faker.py          20      0   100%
utils/exceptions.py                 18      3    83%   42-44
utils/logger.py                     18      1    94%   38
utils/sentiment_analyzer.py         90     23    74%   10-11, 29-31, 49, 66, 68, 78, 80, 174-175, 189-192, 217-223, 240-242
utils/ui.py                         60      0   100%
validate_logic.py                   87     87     0%   7-171
validate_new_features.py           111    111     0%   7-221
--------------------------------------------------------------
TOTAL                             2768   1381    50%
Coverage HTML written to dir htmlcov

FAIL Required test coverage of 70% not reached. Total coverage: 50.11%
=========================== short test summary info ============================
FAILED tests/unit/test_agent_logic.py::test_render_successful_analysis - Valu...
FAILED tests/unit/test_agent_logic.py::test_render_no_news_found - ValueError...
FAILED tests/unit/test_agent_logic.py::test_render_no_ticker_entered - ValueE...
FAILED tests/unit/test_agent_logic.py::test_render_handles_exception - ValueE...
FAILED tests/unit/test_data_detective.py::TestNewFeatures::test_strong_correlation_detection
FAILED tests/unit/test_data_detective.py::TestNewFeatures::test_xls_file_reading
FAILED tests/unit/test_design_system.py::TestDesignSystemModule::test_render_function_exists
FAILED tests/unit/test_design_system.py::TestTabRenderFunctions::test_render_colors_tab
FAILED tests/unit/test_design_system.py::TestTabRenderFunctions::test_render_components_tab
FAILED tests/unit/test_design_system.py::TestTabRenderFunctions::test_render_interactive_tab
FAILED tests/unit/test_design_system.py::TestTabRenderFunctions::test_render_patterns_tab
FAILED tests/unit/test_financial_analyst.py::TestFinancialAnalystRender::test_render_with_valid_ticker
FAILED tests/unit/test_margin_hunter.py::TestMarginHunterRenderFunction::test_render_success_with_valid_inputs
FAILED tests/unit/test_marketing_analytics_data_integration.py::test_get_campaign_data_source_simulate_existing_data
FAILED tests/unit/test_marketing_analytics_data_integration.py::test_render_campaign_dashboard_with_data
=========== 15 failed, 285 passed, 1 skipped, 48 warnings in 31.11s ============
